#+TITLE: parser english transforms

* Overview
  Remember the basic ai that has 5 states and 5 possible actions. Now take
  what we learned from that and compare to an ai attempt with N states and
  N possible actions.

  The way our current parse tree works is we read in input such as
  : Hi how are you?
  and this is transformed to
  : (("Hi" :INTERJECTION :ADJECTIVE)
  :  ("how" :ADVERB :ADJECTIVE :CONJUNCTION :CONJUGATE :NOUN)
  :  ("are" :VERB :NOUN)
  :  ("you" :PRONOUN :DETERMINER)
  :  ("?"  :SYMBOL :INFLICTION))
  Stored in a database we will have to store it as "Hi how are you?", eg
  normal text. However for our lookup we need to reduce similar questions
  to the same representation. In lisp we call this normalization.

  The idea is to reduce many possible input phrases to a single phrase
  that means the same thing in the same context.

*** Data flow
    1) Input vie some method.
    2) tokenization of input.
       1) We parse for word/sentence structure. At some point we need to
          be able to have concrete sentences to work with.
       2) Assuming we have discrete sentences by this point we move on to
          the next step.
    3) Look up parts of speech for all elements.
    4) Transform and reduce the POS set for each sentence paying attention
       to context. This is the last N sentences spoken/parsed before it
       that are related. This step here is what this whole transform
       process is about.
